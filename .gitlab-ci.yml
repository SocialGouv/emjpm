---
variables:
  K8S_NAMESPACE: "${KUBE_NAMESPACE}"
  REMOTE_URL: "https://github.com/${CI_PROJECT_PATH}.git"

  # CI variables
  DOCKER_DRIVER: overlay2
  DOCKER_HOST: tcp://localhost:2375
  GIT_STRATEGY: fetch
  GIT_DEPTH: 5

  # Infra
  IMAGE_INFRA_BASE_NAME: infra/images-docker

  # Globals
  DOCKER_VERSION: "18"
  PYTHON_VERSION: "3.6-alpine"

  PROJECT: emjpm
  RANCHER_PROJECT_ID: c-kk8xm:p-dpgpt

#

stages:
  - "Build"
  - "Deploy"
  - "Notify Finished Deployment"

#

.base_deploy_chart_stage:
  extends: .base_docker_kubectl_image_stage
  script:
    - echo "kubectl config set-context --current --namespace=${K8S_NAMESPACE}"
    - kubectl config set-context --current --namespace=${K8S_NAMESPACE}

    # Set own wildcard when deploying in dev environment
    - >-
      HELM_RENDER_ARGS="
        --set image.tag=${IMAGE_TAG}
        --set ingress.hosts[0].host=${HOST}
        --set ingress.tls[0].hosts[0]=${HOST}
        ${HELM_RENDER_ARGS}"
    # Set own certificate when deploying in prod environment
    - |-
      if [[ -n "${PRODUCTION+x}" ]]; then
        HELM_RENDER_ARGS=" \
          --set ingress.annotations.certmanager\.k8s\.io/cluster-issuer=letsencrypt-prod \
          --set-string ingress.annotations.kubernetes\.io/tls-acme=true \
          ${HELM_RENDER_ARGS}"
      else
        HELM_RENDER_ARGS=" \
          --set ingress.tls[0].secretName=wildcard-crt \
          ${HELM_RENDER_ARGS}"
      fi

    # generate manifest using helm template
    - envsubst < packages/$CONTEXT/.k8s/values.yaml  | helm template ${HELM_RENDER_ARGS} ${CONTEXT} packages/$CONTEXT/.k8s --values - > packages/$CONTEXT/.k8s/manifests/chart-generated.yaml

    # apply manifests
    - kubectl apply -f packages/$CONTEXT/.k8s/manifests

.base_docker_kubectl_image_stage:
  image:
    name: registry.gitlab.factory.social.gouv.fr/devthejo/docker-kubectl-helm:1.0.0
    entrypoint: [""]

.base_create_namespace_stage:
  extends: .base_docker_kubectl_image_stage
  stage: "Build"
  environment:
    name: review/${CI_COMMIT_REF_NAME}-dev
    url: https://${CI_ENVIRONMENT_SLUG}-${CI_PROJECT_ID}.${KUBE_INGRESS_BASE_DOMAIN}
  dependencies: []
  script:
    - echo "kubectl get namespace ${K8S_NAMESPACE}"
    # Skip the job if the namespace exists
    - "[[ $(kubectl get namespace ${K8S_NAMESPACE}) ]] && exit ${CI_JOB_SKIP_EXIT_CODE:-0}"
    #
    - kubectl create namespace ${K8S_NAMESPACE}
    #
    # Use wildcard certificate
    - kubectl label namespace ${K8S_NAMESPACE} cert=wildcard
    #
    # Add git metadata to be able to auto destroy that namespaces
    # see https://github.com/SocialGouv/docker/tree/v0.18.0/k8s-ns-killer
    - kubectl annotate namespace ${K8S_NAMESPACE} git/remote=${REMOTE_URL}
    - kubectl annotate namespace ${K8S_NAMESPACE} git/branch=${CI_COMMIT_REF_NAME}
    #
    # Fake rancher namespace creation
    - "[[ -z ${RANCHER_PROJECT_ID} ]] && exit ${CI_JOB_SKIP_EXIT_CODE:-0}"
    - kubectl annotate namespace ${K8S_NAMESPACE} field.cattle.io/projectId=${RANCHER_PROJECT_ID}
    - kubectl annotate namespace ${K8S_NAMESPACE} field.cattle.io/creatorId=gitlab

.base_docker_image_stage:
  image: docker:19
  services:
    - docker:19-dind

.base_build_stage:
  stage: "Build"
  extends: .base_docker_image_stage
  artifacts:
    expire_in: 1 week
    paths:
      - node_modules
      - packages/$BUILD_NAME/node_modules
  script:
    - echo "$CI_JOB_TOKEN" | docker login $CI_REGISTRY -u gitlab-ci-token --password-stdin
    - >-
      if [[ -n "${CI_COMMIT_TAG}" ]]; then
        export TAG=$(printf "${CI_COMMIT_TAG}" | sed "s/^v//")
        echo "Build ${CI_COMMIT_TAG} tag as ${TAG}"
      else
        export TAG=$CI_COMMIT_REF_SLUG
        echo "Build ${TAG} branch"
      fi
    #
    # NOTE(douglasduteil): aggressive caching strategy.
    # As we don't know which image is the closest to the one we are registering
    # we pull all the images that can help.
    # From the previous commit, to the current branch or the master branch, the
    # first to be defined will be our cache :)
    # NOTE(devthejo): aggressive caching strategy 2 implementation of multistage
    # build strategy.
    - |
      [[ -n "${TRACE}" ]] && set -x

      function set_cache_image() {
        if docker pull ${IMAGE_NAME}:$1; then
          export CACHE_TAG=$1
        fi
      }

      echo ""
      echo "Checking last commit (${CI_COMMIT_BEFORE_SHA}) cache"
      set_cache_image "${CI_COMMIT_BEFORE_SHA}"

      if [[ -z "${CACHE_TAG}" ]]; then
        echo ""
        echo "Checking current branch/tag (${TAG}) cache"
        set_cache_image "${TAG}"
      fi

      if [[ -z "${CACHE_TAG}" ]]; then
        echo ""
        echo "Checking default branch (${CI_DEFAULT_BRANCH}) cache"
        set_cache_image "${CI_DEFAULT_BRANCH}"
      fi

      echo ""
      if [[ -n "${CACHE_TAG}" ]] ; then
        echo "Using ${CACHE_TAG} tag as cache"
      else
        echo "No cache ! Naked build :("
      fi

    - |
      if [[ -n "${MULTISTAGE_BUILD}" ]]; then
        docker build \
          --target pre-dependencies \
          --cache-from ${IMAGE_NAME}.pre-dependencies:${CACHE_TAG} \
          -t ${IMAGE_NAME}.pre-dependencies:${CI_COMMIT_SHA} \
          -t ${IMAGE_NAME}.pre-dependencies:${TAG} \
          $DOCKER_BUILD_ARGS \
          $CONTEXT
        docker push ${IMAGE_NAME}.pre-dependencies:${CI_COMMIT_SHA} &
        docker run ${IMAGE_NAME}.pre-dependencies:${CI_COMMIT_SHA} \
          -v ./node_modules:/app/node_modules \
          -v ./packages/$BUILD_NAME/node_modules:/app/packages/$BUILD_NAME/node_modules \
          yarn --frozen-lockfile --ignore-scripts --production=false
        CONTAINER_ID=$(docker ps -aqn 1)
        docker commit ${CONTAINER_ID} ${IMAGE_NAME}.dependencies:${CI_COMMIT_SHA}
        docker commit ${CONTAINER_ID} ${IMAGE_NAME}.dependencies:${TAG}
        docker rm ${CONTAINER_ID}

        docker build \
          --target builder \
          --cache-from ${IMAGE_NAME}.dependencies:${CACHE_TAG} \
          --cache-from ${IMAGE_NAME}.dependencies:${CI_COMMIT_SHA} \
          --cache-from ${IMAGE_NAME}.builder:${CACHE_TAG} \
          -t ${IMAGE_NAME}.builder:${CI_COMMIT_SHA} \
          -t ${IMAGE_NAME}.builder:${TAG} \
          $DOCKER_BUILD_ARGS \
          $CONTEXT
        docker push ${IMAGE_NAME}.builder:${CI_COMMIT_SHA} &

        docker build \
          --target server \
          --cache-from ${IMAGE_NAME}.builder:${CACHE_TAG} \
          --cache-from ${IMAGE_NAME}.builder:${CI_COMMIT_SHA} \
          --cache-from ${IMAGE_NAME}:${CACHE_TAG} \
          -t ${IMAGE_NAME}:${CI_COMMIT_SHA} \
          -t ${IMAGE_NAME}:${TAG} \
          $DOCKER_BUILD_ARGS \
          $CONTEXT
        docker push ${IMAGE_NAME}:${CI_COMMIT_SHA} &
      else
        docker build \
          --cache-from ${IMAGE_NAME}:${CACHE_TAG} \
          -t ${IMAGE_NAME}:${CI_COMMIT_SHA} \
          -t ${IMAGE_NAME}:${TAG} \
          $DOCKER_BUILD_ARGS \
          $CONTEXT
        docker push ${IMAGE_NAME}:${CI_COMMIT_SHA} &
      fi

      wait

      docker push ${IMAGE_NAME}.builder:${TAG} &
      docker push ${IMAGE_NAME}:${TAG} &

      wait

#
.notify_stage: &notify_stage
  image: registry.gitlab.factory.social.gouv.fr/socialgouv/docker/git-deploy:0.24.0
  dependencies: []

.base_notify_pending_stage:
  <<: *notify_stage
  script:
    #
    - create-deployment
    - cat /tmp/deploy_payload.json
    #
    - extract-deploy-id
    - echo "GitHub deployment id '$(cat DEPLOY_ID)'"
  artifacts:
    expire_in: 1 day
    paths:
      - DEPLOY_ID

.resolve_deploy_environment: &resolve_deploy_environment |
  set -x

  if [[ -n "${PRODUCTION+x}" ]]; then
    export ENVIRONMENT="production"
  else
    export ENVIRONMENT=${ENVIRONMENT:-"staging"}
  fi

.base_notify_fail_stage:
  <<: *notify_stage
  allow_failure: true
  when: on_failure
  script:
    - *resolve_deploy_environment
    - update-deployment $(cat DEPLOY_ID) "${HOST}" failure

.base_notify_success_stage:
  <<: *notify_stage
  when: on_success
  script:
    - *resolve_deploy_environment
    - update-deployment $(cat DEPLOY_ID) "${HOST}" success


#

.base_trivy_scan:
  stage: Deploy
  services:
    - docker:dind
  image: registry.gitlab.factory.social.gouv.fr/socialgouv/docker/trivy:2.9.0
  allow_failure: true
  variables:
    IMAGE: $CI_REGISTRY_IMAGE/$CONTEXT:$CI_COMMIT_SHA
  script:
    # Build report
    - trivy --cache-dir .trivycache/ image --exit-code 0 --no-progress --format template --template "@/tmp/contrib/gitlab.tpl" -o gl-container-scanning-report.json $IMAGE
    # Print report and fail on error
    - trivy --cache-dir .trivycache/ image --exit-code 1 --no-progress $IMAGE
  cache:
    paths:
      - .trivycache/
  # Enables https://docs.gitlab.com/ee/user/application_security/container_scanning/ (Container Scanning report is available on GitLab EE Ultimate or GitLab.com Gold)
  artifacts:
    reports:
      container_scanning: gl-container-scanning-report.json

#

.base_notify_mattermost:
  image: registry.gitlab.factory.social.gouv.fr/devthejo/bash-curl:1.0.1
  dependencies: []
  before_script:
    - HOST="https://${CI_ENVIRONMENT_SLUG}-${CI_PROJECT_NAME}.${KUBE_INGRESS_BASE_DOMAIN}"

.base_notify_deploying_production_mattermost:
  extends: .base_notify_mattermost
  when: on_success
  stage: Notify Finished Deployment
  only:
    refs:
      - tags
  script:
    - |
      NOTIF_MSG=$(echo "
      `./scripts/gitops/get-last-version-changes`
      -----
      ${HOST}
      " | sed -z 's/\n/\\n/g')
    - |
      echo '{"username":"SocialGroovyBot","icon_url":"https://avatars2.githubusercontent.com/u/45039513","text":"'${NOTIF_MSG}'"}' \
        | curl -H 'Content-Type: application/json' ${MATTERMOST_WEBHOOK} -d @-

#

variables:
  K8S_NAMESPACE_PREFIX: "${PROJECT}-feature"

.base_delete_useless_k8s_ns_stage:
  stage: Notify Finished Deployment
  dependencies: []
  allow_failure: true
  image: registry.gitlab.factory.social.gouv.fr/socialgouv/docker/k8s-ns-killer:0.24.0
  environment: fabrique-dev
  script:
    - git remote set-url origin https://github.com/${CI_PROJECT_PATH}.git
    - echo "k8s-ns-killer ${K8S_NAMESPACE_PREFIX}"
    # - k8s-ns-killer ${K8S_NAMESPACE_PREFIX}
    # Debug mode
    - sh -x /bin/k8s-ns-killer ${K8S_NAMESPACE_PREFIX}
  only:
    - master

#

.base_delete_useless_managed_postgresql_stage:
  stage: Notify Finished Deployment
  dependencies: []
  allow_failure: true
  image: registry.gitlab.factory.social.gouv.fr/socialgouv/docker/pg-cleaner:0.24.0
  environment: fabrique-dev
  script:
    - python /bin/pg-cleaner.py
  only:
    - master


.base_stage:
  except:
    variables:
      # Don't run when running e2e tests
      - $E2E_TEST
      # Don't run when deploying in production an existing image
      - $PRODUCTION
      # Don't run when tagging a commit
      - $RELEASE

# #

.incubateur_stage:
  environment:
    name: prod2
  only:
    variables:
      - $PRODUCTION

.dev_stage:
  extends:
    - .base_stage
  environment:
    name: fabrique-dev2

.build_stage:
  extends: .base_stage
  stage: Build
  interruptible: true
  dependencies: []
  # artifacts:
  #   paths:
  #     - /*.docker.tar.gz
  #   expire_in: 1 week
  # before_script:
  # - |
  #   if [ -f "$BUILD_NAME.docker.tar.gz" ]; then
  #     docker load --input /$BUILD_NAME.docker.tar.gz
  #   fi
  # after_script:
  #   - docker save $DOCKER_CI_IMAGE | gzip > /$BUILD_NAME.docker.tar.gz

################### CREATE NAMESPACE ##############

Create namespace:
  extends:
    - .base_create_namespace_stage
    - .dev_stage
  before_script:
    - source ./.gitlab-ci/env.sh
  after_script:
    - source ./.gitlab-ci/env.sh
    - kubectl config set-context --current --namespace=${K8S_NAMESPACE}
    #
    # Create secrets
    - export APP_URL=$(echo $FRONTEND_URL | base64)
    - envsubst < ./.k8s/secret-dev.yml > ./secret-dev.yml
    - kubectl apply -f ./secret-dev.yml -n ${K8S_NAMESPACE}
    #
    # Create azure volume secrets for anonymized export
    - export AZURE_STORAGE_ACCOUNT_NAME=$(kubectl get secret azure-${K8S_PROJECT}dev-volume -n ${K8S_PROJECT}-secret -ojsonpath='{.data.azurestorageaccountname}')
    - export AZURE_STORAGE_ACCOUNT_KEY=$(kubectl get secret azure-${K8S_PROJECT}dev-volume -n ${K8S_PROJECT}-secret -ojsonpath='{.data.azurestorageaccountkey}')
    - envsubst < .k8s/azure-volume-secret.yml > ./azure-volume-secret.yml
    - kubectl apply -f ./azure-volume-secret.yml -n ${K8S_NAMESPACE}

################### Build API ##################

Build api image:
  extends:
    - .base_build_stage
    - .build_stage
  variables:
    BUILD_NAME: api
    CONTEXT: .
    DOCKER_BUILD_ARGS: >-
      -f ./packages/api/Dockerfile
    IMAGE_NAME: $CI_REGISTRY_IMAGE/api
    MULTISTAGE_BUILD: "true"

################### Build APP ##################

.build_app:
  extends:
    - .base_build_stage
    - .build_stage
  before_script:
    - source ./.gitlab-ci/env.sh
    - >-
      export DOCKER_BUILD_ARGS="
        --build-arg REACT_APP_SENTRY_PUBLIC_DSN=${SENTRY_PUBLIC_DSN}
        --build-arg REACT_APP_GRAPHQL_SERVER_URI=//${HASURA_HOST}/v1/graphql
        --build-arg REACT_APP_API_URL=//${API_HOST}
        --shm-size 2G
        -f ./packages/app/Dockerfile"
  variables:
    BUILD_NAME: app
    CONTEXT: .
    IMAGE_NAME: $CI_REGISTRY_IMAGE/app
    MULTISTAGE_BUILD: "true"

Build app image (dev):
  extends:
    - .build_app
  except:
    - tags

Build app image (prod):
  extends:
    - .build_app
  only:
    refs:
      - tags
  variables:
    BUILD_PRODUCTION: "true"

################### Build HASURA ########################

Build hasura image:
  extends:
    - .base_build_stage
    - .build_stage
  variables:
    BUILD_NAME: hasura
    CONTEXT: packages/hasura
    IMAGE_NAME: $CI_REGISTRY_IMAGE/hasura

Backup PG before production (incubateur):
  extends:
    - .base_docker_kubectl_image_stage
    - .incubateur_stage
  stage: Build
  interruptible: true
  script:
    - source ./.gitlab-ci/env.sh
    - kubectl config set-context --current --namespace=${K8S_NAMESPACE}

    - export PG_HOST=$(kubectl get secret azure-pg-admin-user -n ${K8S_PROJECT}-secret -ojsonpath='{.data.PG_HOST}' | base64 --decode)

    - export ADMIN_PG_USER=$(kubectl get secret azure-pg-admin-user -n ${K8S_PROJECT}-secret -ojsonpath='{.data.ADMIN_PG_USER}' | base64 --decode)
    - export ADMIN_PG_PASSWORD=$(kubectl get secret azure-pg-admin-user -n ${K8S_PROJECT}-secret -ojsonpath='{.data.ADMIN_PG_PASSWORD}' | base64 --decode)

    - kubectl delete configmap ${K8S_PROJECT}-backup-configmap-${BRANCH_HASH} || true
    - kubectl create configmap ${K8S_PROJECT}-backup-configmap-${BRANCH_HASH}
      --from-file=./.k8s/postgres/backup/configmap/

    - kubectl delete job ${K8S_PROJECT}-backup-${BRANCH_HASH} || true
    - cat .k8s/postgres/backup/job.yml | envsubst | kubectl apply -f -;

################### MANAGED PG Initialisation ##################

Init Managed Database:
  extends:
    - .base_docker_kubectl_image_stage
    - .dev_stage
    - .deploy_stage
  script:
    - source ./.gitlab-ci/env.sh
    - kubectl config set-context --current --namespace=${K8S_NAMESPACE}

    - "[[ $(kubectl get po -l 'app=init-azure-pg-job' --field-selector status.phase=Succeeded --field-selector status.phase=Running --field-selector status.phase=Pending) ]] && exit ${CI_JOB_SKIP_EXIT_CODE:-0}"

    - export PG_HOST=$(kubectl get secret azure-pg-admin-user -n ${K8S_PROJECT}-secret -ojsonpath='{.data.PG_HOST}' | base64 --decode)
    - export EMJPM_PG_USER=$(kubectl get secret azure-pg-emjpm-user -n ${K8S_PROJECT}-secret -ojsonpath='{.data.EMJPM_PG_USER}' | base64 --decode)
    - export EMJPM_PG_PASSWORD=$(kubectl get secret azure-pg-emjpm-user -n ${K8S_PROJECT}-secret -ojsonpath='{.data.EMJPM_PG_PASSWORD}' | base64 --decode)

    #
    - kubectl delete configmap ${K8S_PROJECT}-init-db-${BRANCH_HASH} || true
    - kubectl create configmap ${K8S_PROJECT}-init-db-${BRANCH_HASH}
      --from-file=./.k8s/postgres/init/configmap/
    #
    - kubectl delete job init-azure-pg-job || true
    - cat ./.k8s/postgres/init/init-azure-pg-job.yml | envsubst | kubectl apply -f -
    - kubectl wait --for=condition=complete job/init-azure-pg-job  --timeout=300s


# DEPLOY

.deploy_stage:
  stage: Deploy
  dependencies: []
  services:
    - docker:dind
  variables:
    IMAGE_TAG: ${CI_COMMIT_SHA}
    REGISTRY: ${CI_REGISTRY_IMAGE}

############### Deploy API ###########################

.deploy_api_stage:
  extends:
    - .base_deploy_chart_stage
    - .deploy_stage
  dependencies: []
  variables:
    CONTEXT: api
    PORT: 4000
  before_script:
    - source ./.gitlab-ci/env.sh
    - kubectl config set-context --current --namespace=${K8S_NAMESPACE}
    #
    - export PG_HOST=$(kubectl get secret azure-pg-admin-user -n ${K8S_PROJECT}-secret -ojsonpath='{.data.PG_HOST}' | base64 --decode)
    - export EMJPM_PG_USER_ENCODED=$(kubectl get secret azure-pg-emjpm-user -n ${K8S_PROJECT}-secret -ojsonpath='{.data.EMJPM_PG_USER_ENCODED}' | base64 --decode)
    - export EMJPM_PG_PASSWORD_ENCODED=$(kubectl get secret azure-pg-emjpm-user -n ${K8S_PROJECT}-secret -ojsonpath='{.data.EMJPM_PG_PASSWORD_ENCODED}' | base64 --decode)
    #
    - HOST=${API_HOST}

#

Deploy api (dev):
  extends:
    - .deploy_api_stage
    - .dev_stage
  variables:
    HELM_RENDER_ARGS: >-
      --set deployment.resources.requests.memory=128Mi
      --set deployment.resources.requests.cpu=1m
      --set ingress.annotations.certmanager\.k8s\.io/cluster-issuer=null
      --set ingress.annotations.kubernetes\.io/tls-acme=null

Deploy api (prod):
  extends:
    - .deploy_api_stage
    - .incubateur_stage

############### Deploy APP ###############################

.deploy_app_stage:
  extends:
    - .base_deploy_chart_stage
    - .deploy_stage
  variables:
    CONTEXT: app
    PORT: 3000
  before_script:
    - source ./.gitlab-ci/env.sh
    - kubectl config set-context --current --namespace=${K8S_NAMESPACE}
    #
    - HOST=${FRONTEND_HOST}

#

Deploy app (dev):
  extends:
    - .deploy_app_stage
    - .dev_stage
  variables:
    HELM_RENDER_ARGS: >-
      --set deployment.resources.requests.memory=128Mi
      --set ingress.annotations.certmanager\.k8s\.io/cluster-issuer=null
      --set ingress.annotations.kubernetes\.io/tls-acme=null

Deploy app (prod):
  extends:
    - .deploy_app_stage
    - .incubateur_stage
  after_script:
    - source ./.gitlab-ci/env.sh
    - kubectl config set-context --current --namespace=${K8S_NAMESPACE}
    - kubectl apply -f ./.k8s/app-redirect.yml -n ${K8S_NAMESPACE}

# Deploy KNEX #################################

.deploy_knex_stage:
  extends:
    - .base_docker_kubectl_image_stage
    - .deploy_stage
  dependencies: []
  variables:
    CONTEXT: knex
  script:
    - source ./.gitlab-ci/env.sh
    - kubectl config set-context --current --namespace=${K8S_NAMESPACE}
    #
    - export PG_HOST=$(kubectl get secret azure-pg-admin-user -n ${K8S_PROJECT}-secret -ojsonpath='{.data.PG_HOST}' | base64 --decode)
    #
    # Backup cronjob
    - export ADMIN_PG_USER=$(kubectl get secret azure-pg-admin-user -n ${K8S_PROJECT}-secret -ojsonpath='{.data.ADMIN_PG_USER}' | base64 --decode)
    - export ADMIN_PG_PASSWORD=$(kubectl get secret azure-pg-admin-user -n ${K8S_PROJECT}-secret -ojsonpath='{.data.ADMIN_PG_PASSWORD}' | base64 --decode)

    - kubectl delete configmap ${K8S_PROJECT}-backup-configmap-${BRANCH_HASH} || true;
    - kubectl create configmap ${K8S_PROJECT}-backup-configmap-${BRANCH_HASH}
      --from-file=./.k8s/postgres/backup/configmap
    #
    - if [ -n "${PRODUCTION+x}" ]; then
      kubectl delete cronjob ${K8S_PROJECT}-backup-${BRANCH_HASH} || true;
      cat ./.k8s/postgres/backup/cronjob.yml | envsubst | kubectl apply -f -;
      fi

#

Deploy knex (dev):
  extends:
    - .deploy_knex_stage
    - .dev_stage

Deploy knex (prod):
  extends:
    - .deploy_knex_stage
    - .incubateur_stage

################ Deploy HASURA #################################

.deploy_hasura_stage:
  extends:
    - .base_deploy_chart_stage
    - .deploy_stage
  variables:
    CONTEXT: hasura
    PORT: 80
  before_script:
    - source ./.gitlab-ci/env.sh
    - kubectl config set-context --current --namespace=${K8S_NAMESPACE}
    #
    - HOST=${HASURA_HOST}
    #
    - export PG_HOST=$(kubectl get secret azure-pg-admin-user -n ${K8S_PROJECT}-secret -ojsonpath='{.data.PG_HOST}' | base64 --decode)
    - export POSTGRES_EMJPM_USER_ENCODED=$(kubectl get secret azure-pg-emjpm-user -n ${K8S_PROJECT}-secret -ojsonpath='{.data.EMJPM_PG_USER_ENCODED}' | base64 --decode)
    - export POSTGRES_EMJPM_PASSWORD_ENCODED=$(kubectl get secret azure-pg-emjpm-user -n ${K8S_PROJECT}-secret -ojsonpath='{.data.EMJPM_PG_PASSWORD_ENCODED}' | base64 --decode)

#

Deploy hasura (dev):
  extends:
    - .deploy_hasura_stage
    - .dev_stage
  variables:
    HELM_RENDER_ARGS: >-
      --set deployment.resources.requests.memory=128Mi
      --set deployment.resources.requests.cpu=5m
      --set ingress.annotations.certmanager\.k8s\.io/cluster-issuer=null
      --set ingress.annotations.kubernetes\.io/tls-acme=null

Deploy hasura (prod):
  extends:
    - .deploy_hasura_stage
    - .incubateur_stage

################### Restore DATA #############################

Restore postgres data:
  extends:
    - .base_docker_kubectl_image_stage
    - .dev_stage
    - .deploy_stage
  when: manual
  script:
    - source ./.gitlab-ci/env.sh

    - kubectl config set-context --current --namespace=${K8S_NAMESPACE}

    - export PG_HOST=$(kubectl get secret azure-pg-admin-user -n ${K8S_PROJECT}-secret -ojsonpath='{.data.PG_HOST}' | base64 --decode)

    - export EMJPM_PG_USER=$(kubectl get secret azure-pg-emjpm-user -n ${K8S_PROJECT}-secret -ojsonpath='{.data.EMJPM_PG_USER}' | base64 --decode)
    - export EMJPM_PG_PASSWORD=$(kubectl get secret azure-pg-emjpm-user -n ${K8S_PROJECT}-secret -ojsonpath='{.data.EMJPM_PG_PASSWORD}' | base64 --decode)

    - kubectl scale --replicas=0 deploy/${HASURA_SRV_HOST}

    - kubectl delete configmap ${K8S_PROJECT}-restore-configmap-${BRANCH_HASH} || true
    - kubectl create configmap ${K8S_PROJECT}-restore-configmap-${BRANCH_HASH}
      --from-file=./.k8s/postgres/restore/configmap/

    - kubectl delete job restore-job || true
    - cat ./.k8s/postgres/restore/restore-job.yml | envsubst | kubectl apply -f -

    - kubectl wait --for=condition=complete job/restore-job  --timeout=600s
    - kubectl scale --replicas=1 deploy/${HASURA_SRV_HOST}
    - kubectl rollout status deploy/${HASURA_SRV_HOST} --timeout=600s

    - kubectl delete job anonymise-job || true
    - cat ./.k8s/postgres/restore/anonymise-job.yml | envsubst | kubectl apply -f -
    - kubectl wait --for=condition=complete job/anonymise-job  --timeout=600s

# NOTIFY

Notify Starting Deployment:
  extends:
    - .base_notify_pending_stage
    - .base_stage
  stage: Deploy

Notify Fail:
  extends:
    - .base_notify_fail_stage
    - .base_stage
  stage: Notify Finished Deployment
  dependencies:
    - Notify Starting Deployment
  before_script:
    - source ./.gitlab-ci/env.sh
    - HOST=${FRONTEND_HOST}

Notify Success:
  extends:
    - .base_notify_success_stage
    - .base_stage
  stage: Notify Finished Deployment
  dependencies:
    - Notify Starting Deployment
  before_script:
    - source ./.gitlab-ci/env.sh
    - HOST=${FRONTEND_HOST}

############ Delete useless K8s ns #################

Delete useless k8s namespaces:
  extends:
    - .base_delete_useless_k8s_ns_stage
    - .base_stage

############ Release #################

Release:
  stage: Notify Finished Deployment
  dependencies: []
  image: node:15-alpine
  variables:
    LERNA_ARGS: --force-publish --yes
    #
    GIT_AUTHOR_EMAIL: 45039513+SocialGroovyBot@users.noreply.github.com
    GIT_AUTHOR_NAME: Social Groovy Bot
    GIT_COMMITTER_EMAIL: $GIT_AUTHOR_EMAIL
    GIT_COMMITTER_NAME: $GIT_AUTHOR_NAME
    GIT_DEPTH: 4242
  only:
    variables:
      - $RELEASE
  cache:
    key: "$CI_JOB_NAME-$CI_COMMIT_REF_SLUG"
    paths:
      - node_modules
      - $CI_PROJECT_DIR/.yarn
  before_script:
  script:
    # Ensure to have "git" and "jq"
    - apk add --no-cache git=~2 jq=~1
    # Set git to a branch
    - git checkout ${CI_COMMIT_REF_NAME}
    # Use github as origin
    - git remote set-url origin https://${GITHUB_TOKEN}@github.com/${CI_PROJECT_PATH}.git

    # Use local yarn cache
    - yarn config set cache-folder $CI_PROJECT_DIR/.yarn
    # Should only install workspace dependencies
    - yarn --frozen-lockfile

    # HACK(douglasduteil): remove all packages dependencies
    # Restore the package files before bumping versions.
    # As Lerna will commit, we need to restore the files as they were
    - git checkout -- .

    # Run lerna version
    - echo "yarn lerna version ${LERNA_ARGS}"
    - GH_TOKEN=${GITHUB_TOKEN} yarn lerna version ${LERNA_ARGS}

############ Trigger production ###################

Trigger production:
  extends: .base_stage
  stage: Notify Finished Deployment
  image: curlimages/curl:7.73.0
  variables:
    GIT_STRATEGY: none
  only:
    refs:
      - tags
  script:
    - curl --request POST
      --form ref="${CI_COMMIT_REF_NAME}"
      --form token="${CI_JOB_TOKEN}"
      --form variables[PRODUCTION]="true"
      ${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/trigger/pipeline

############ Trigger release ########################

Trigger release:
  extends: .base_stage
  stage: Notify Finished Deployment
  image: curlimages/curl:7.73.0
  when: manual
  variables:
    GIT_STRATEGY: none
  only:
    refs:
      - master
  script:
    - curl --request POST
      --form ref="${CI_COMMIT_REF_NAME}"
      --form token="${CI_JOB_TOKEN}"
      --form variables[RELEASE]="true"
      ${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/trigger/pipeline

############ Security scans ########################
Trivy Scan api:
  extends: .base_trivy_scan
  variables:
    CONTEXT: api

Trivy Scan app:
  extends: .base_trivy_scan
  variables:
    CONTEXT: app

Trivy Scan hasura:
  extends: .base_trivy_scan
  variables:
    CONTEXT: hasura

############ Notify production ########################

Notify Production (mattermost):
  extends: .base_notify_deploying_production_mattermost